{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPz9AW98g0XA35eZhJ2WZeP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekkiprop/llms/blob/main/03_Godoy_FT_Low_Rank_Adaptation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wqOF_rkv0Ez_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7aa368-85e1-4133-c7b6-413b9b91bdf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch~=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "from numpy.linalg import matrix_rank\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, AutoConfig\n",
        "from transformers.integrations.bitsandbytes import get_keys_to_not_convert\n",
        "from bitsandbytes.nn import Linear8bitLt, Linear4bit, LinearFP4,  LinearNF4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_layer = nn.Linear(1024, 1024, bias = False)\n",
        "base_layer.weight.shape, base_layer.weight.numel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpdNEI9y0jnv",
        "outputId": "b874c488-1221-49f2-b9d8-b3298f175af9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1024, 1024]), 1048576)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(11)\n",
        "r = 8\n",
        "layer_A = nn.Linear(base_layer.in_features, r, bias=False)\n",
        "layer_B = nn.Linear(r, base_layer.out_features, bias=False)\n",
        "layer_A, layer_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAJLidD10t2U",
        "outputId": "34cc8830-516d-4b5a-f43d-75ac09122b86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Linear(in_features=1024, out_features=8, bias=False),\n",
              " Linear(in_features=8, out_features=1024, bias=False))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "layer_A.weight.numel(), layer_B.weight.numel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhwY_KJy07QU",
        "outputId": "aa060b25-d2fd-4eb1-d4ac-a2a0acee3f78"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8192, 8192)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "composite = layer_B.weight @ layer_A.weight"
      ],
      "metadata": {
        "id": "zNfh4q7s1CnK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composite.shape, composite.numel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBv5FH5u1IsJ",
        "outputId": "ad455b32-d8f7-4d63-978a-4f942c11336d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1024, 1024]), 1048576)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_rank(composite.detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkWQ7JMr1iiv",
        "outputId": "9c66c519-eaf4-42b9-844b-3523cb7c1e96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ther=torch.linalg.matrix_rank(composite.detach())\n",
        "ther"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OishURC1-q-",
        "outputId": "6a467de1-4dca-473f-f633-4ed0983fbccc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_rank(composite.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uu8eiSs2vLd",
        "outputId": "9a2a9f05-43b3-4689-c9a4-eb20ecbb3a4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(19)\n",
        "batch = torch.randn(1, 1024)\n",
        "batch @ (base_layer.weight.data + layer_B.weight @ layer_A.weight).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIWnRZ5O4WXy",
        "outputId": "454ec36e-65fc-4feb-d1b5-e8c474fa8c05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2958, -0.1800, -0.3731,  ..., -0.1412,  0.7358,  0.4212]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_layer.weight.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSby2S0w5Jn6",
        "outputId": "8c525760-275c-4972-8ac2-3487e578fb9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regular_output = batch @ base_layer.weight.data.T\n",
        "additional_outputA = batch @ (layer_B.weight @ layer_A.weight).T\n",
        "regular_output.shape, additional_outputA.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lVJrWsD5bpY",
        "outputId": "38de1831-4d2a-4d42-d842-0b5762cae73d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1024]), torch.Size([1, 1024]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "additional_outputA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD5s7SYX8gFw",
        "outputId": "7ba096e6-09d5-4514-dae3-4f6f000bc4c8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0357,  0.0230, -0.4607,  ..., -0.2920,  0.1944,  0.5041]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_A = (batch @ layer_A.weight.T)\n",
        "add_out = out_A @ layer_B.weight.T\n",
        "add_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME2nMRQy87in",
        "outputId": "f65b9f96-ca74-476b-f0fd-c39ecbc9f832"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0357,  0.0230, -0.4607,  ..., -0.2920,  0.1944,  0.5041]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regular_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWzJhWtv-fd4",
        "outputId": "b8fcbfb6-dffe-461f-c783-4f138d5f1d86"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3315, -0.2030,  0.0876,  ...,  0.1508,  0.5414, -0.0829]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output   = regular_output + add_out"
      ],
      "metadata": {
        "id": "mGMo-aNs-nEu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ysyDtcV-zaP",
        "outputId": "a73a33e5-9184-4c4a-c791-085aa8d4e07c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2958, -0.1800, -0.3731,  ..., -0.1412,  0.7358,  0.4212]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha  =  2*r\n",
        "output = regular_output + (alpha/r) * additional_outputA\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eErT2GIX-_nt",
        "outputId": "921a5b58-c977-45c6-f84a-20fdef673114"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2600, -0.1569, -0.8338,  ..., -0.4332,  0.9301,  0.9253]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=compute_dtype\n",
        ")\n",
        "\n",
        "model_q4 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                torch_dtype=compute_dtype,\n",
        "                                                quantization_config=nf4_config)"
      ],
      "metadata": {
        "id": "RFXXLUHG-0Q7"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainable_parms(model):\n",
        "    parms = [(name, param.dtype) for name, param in model.named_parameters() if param.requires_grad]\n",
        "    return parms\n",
        "\n",
        "trainable_parms(model_q4.model)"
      ],
      "metadata": {
        "id": "-oRQX7qB_LOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcd26f2-485e-4e9b-c201-178207d3d97e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('decoder.embed_tokens.weight', torch.float32),\n",
              " ('decoder.embed_positions.weight', torch.float32),\n",
              " ('decoder.layers.0.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.0.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.0.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.0.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.1.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.1.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.1.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.1.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.2.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.2.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.2.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.2.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.3.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.3.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.3.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.3.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.4.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.4.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.4.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.4.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.5.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.5.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.5.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.5.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.6.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.6.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.6.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.6.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.7.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.7.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.7.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.7.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.8.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.8.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.8.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.8.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.9.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.9.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.9.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.9.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.10.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.10.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.10.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.10.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.11.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.11.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.11.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.11.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.12.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.12.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.12.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.12.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.13.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.13.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.13.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.13.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.14.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.14.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.14.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.14.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.15.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.15.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.15.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.15.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.16.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.16.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.16.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.16.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.17.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.17.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.17.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.17.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.18.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.18.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.18.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.18.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.19.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.19.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.19.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.19.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.20.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.20.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.20.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.20.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.21.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.21.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.21.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.21.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.22.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.22.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.22.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.22.final_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.23.self_attn_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.23.self_attn_layer_norm.bias', torch.float32),\n",
              " ('decoder.layers.23.final_layer_norm.weight', torch.float32),\n",
              " ('decoder.layers.23.final_layer_norm.bias', torch.float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_model = prepare_model_for_kbit_training(model_q4,\n",
        "                                        use_gradient_checkpointing=True,\n",
        "                                        gradient_checkpointing_kwargs={'use_reentrant': False})\n",
        "prepared_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8eFmblLB7WH",
        "outputId": "0170b287-be56-4c3c-944d-22fe39f8e484"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OPTForCausalLM(\n",
              "  (model): OPTModel(\n",
              "    (decoder): OPTDecoder(\n",
              "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
              "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
              "      (project_out): Linear4bit(in_features=1024, out_features=512, bias=False)\n",
              "      (project_in): Linear4bit(in_features=512, out_features=1024, bias=False)\n",
              "      (layers): ModuleList(\n",
              "        (0-23): 24 x OPTDecoderLayer(\n",
              "          (self_attn): OPTSdpaAttention(\n",
              "            (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNFVESgGIXZn"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fTIOULCJOSmd"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_parms(model_q4.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oqq77PzJGIM",
        "outputId": "6ba53058-9a01-40d4-a527-42b03bef4c2f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Q7IXeN3yMHZi",
        "outputId": "d82e0129-aca7-4c8a-836c-06a03fb4f260"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'parm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-327cc8c557ff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'parm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parms_of_dtype(model, dtype=torch.float32):\n",
        "  parms = [name for name, param in model.named_parameters() if param.dtype == dtype]\n",
        "  return parms\n",
        "\n",
        "parms_of_dtype(prepared_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk7dAyzBJXOe",
        "outputId": "2a637943-2cd4-4d26-c90f-03c8df82981e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.decoder.embed_tokens.weight',\n",
              " 'model.decoder.embed_positions.weight',\n",
              " 'model.decoder.layers.0.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.0.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.0.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.0.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.0.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.0.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.0.fc1.bias',\n",
              " 'model.decoder.layers.0.fc2.bias',\n",
              " 'model.decoder.layers.0.final_layer_norm.weight',\n",
              " 'model.decoder.layers.0.final_layer_norm.bias',\n",
              " 'model.decoder.layers.1.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.1.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.1.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.1.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.1.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.1.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.1.fc1.bias',\n",
              " 'model.decoder.layers.1.fc2.bias',\n",
              " 'model.decoder.layers.1.final_layer_norm.weight',\n",
              " 'model.decoder.layers.1.final_layer_norm.bias',\n",
              " 'model.decoder.layers.2.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.2.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.2.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.2.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.2.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.2.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.2.fc1.bias',\n",
              " 'model.decoder.layers.2.fc2.bias',\n",
              " 'model.decoder.layers.2.final_layer_norm.weight',\n",
              " 'model.decoder.layers.2.final_layer_norm.bias',\n",
              " 'model.decoder.layers.3.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.3.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.3.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.3.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.3.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.3.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.3.fc1.bias',\n",
              " 'model.decoder.layers.3.fc2.bias',\n",
              " 'model.decoder.layers.3.final_layer_norm.weight',\n",
              " 'model.decoder.layers.3.final_layer_norm.bias',\n",
              " 'model.decoder.layers.4.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.4.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.4.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.4.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.4.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.4.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.4.fc1.bias',\n",
              " 'model.decoder.layers.4.fc2.bias',\n",
              " 'model.decoder.layers.4.final_layer_norm.weight',\n",
              " 'model.decoder.layers.4.final_layer_norm.bias',\n",
              " 'model.decoder.layers.5.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.5.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.5.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.5.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.5.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.5.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.5.fc1.bias',\n",
              " 'model.decoder.layers.5.fc2.bias',\n",
              " 'model.decoder.layers.5.final_layer_norm.weight',\n",
              " 'model.decoder.layers.5.final_layer_norm.bias',\n",
              " 'model.decoder.layers.6.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.6.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.6.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.6.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.6.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.6.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.6.fc1.bias',\n",
              " 'model.decoder.layers.6.fc2.bias',\n",
              " 'model.decoder.layers.6.final_layer_norm.weight',\n",
              " 'model.decoder.layers.6.final_layer_norm.bias',\n",
              " 'model.decoder.layers.7.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.7.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.7.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.7.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.7.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.7.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.7.fc1.bias',\n",
              " 'model.decoder.layers.7.fc2.bias',\n",
              " 'model.decoder.layers.7.final_layer_norm.weight',\n",
              " 'model.decoder.layers.7.final_layer_norm.bias',\n",
              " 'model.decoder.layers.8.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.8.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.8.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.8.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.8.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.8.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.8.fc1.bias',\n",
              " 'model.decoder.layers.8.fc2.bias',\n",
              " 'model.decoder.layers.8.final_layer_norm.weight',\n",
              " 'model.decoder.layers.8.final_layer_norm.bias',\n",
              " 'model.decoder.layers.9.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.9.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.9.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.9.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.9.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.9.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.9.fc1.bias',\n",
              " 'model.decoder.layers.9.fc2.bias',\n",
              " 'model.decoder.layers.9.final_layer_norm.weight',\n",
              " 'model.decoder.layers.9.final_layer_norm.bias',\n",
              " 'model.decoder.layers.10.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.10.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.10.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.10.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.10.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.10.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.10.fc1.bias',\n",
              " 'model.decoder.layers.10.fc2.bias',\n",
              " 'model.decoder.layers.10.final_layer_norm.weight',\n",
              " 'model.decoder.layers.10.final_layer_norm.bias',\n",
              " 'model.decoder.layers.11.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.11.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.11.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.11.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.11.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.11.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.11.fc1.bias',\n",
              " 'model.decoder.layers.11.fc2.bias',\n",
              " 'model.decoder.layers.11.final_layer_norm.weight',\n",
              " 'model.decoder.layers.11.final_layer_norm.bias',\n",
              " 'model.decoder.layers.12.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.12.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.12.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.12.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.12.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.12.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.12.fc1.bias',\n",
              " 'model.decoder.layers.12.fc2.bias',\n",
              " 'model.decoder.layers.12.final_layer_norm.weight',\n",
              " 'model.decoder.layers.12.final_layer_norm.bias',\n",
              " 'model.decoder.layers.13.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.13.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.13.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.13.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.13.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.13.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.13.fc1.bias',\n",
              " 'model.decoder.layers.13.fc2.bias',\n",
              " 'model.decoder.layers.13.final_layer_norm.weight',\n",
              " 'model.decoder.layers.13.final_layer_norm.bias',\n",
              " 'model.decoder.layers.14.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.14.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.14.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.14.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.14.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.14.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.14.fc1.bias',\n",
              " 'model.decoder.layers.14.fc2.bias',\n",
              " 'model.decoder.layers.14.final_layer_norm.weight',\n",
              " 'model.decoder.layers.14.final_layer_norm.bias',\n",
              " 'model.decoder.layers.15.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.15.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.15.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.15.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.15.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.15.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.15.fc1.bias',\n",
              " 'model.decoder.layers.15.fc2.bias',\n",
              " 'model.decoder.layers.15.final_layer_norm.weight',\n",
              " 'model.decoder.layers.15.final_layer_norm.bias',\n",
              " 'model.decoder.layers.16.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.16.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.16.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.16.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.16.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.16.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.16.fc1.bias',\n",
              " 'model.decoder.layers.16.fc2.bias',\n",
              " 'model.decoder.layers.16.final_layer_norm.weight',\n",
              " 'model.decoder.layers.16.final_layer_norm.bias',\n",
              " 'model.decoder.layers.17.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.17.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.17.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.17.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.17.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.17.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.17.fc1.bias',\n",
              " 'model.decoder.layers.17.fc2.bias',\n",
              " 'model.decoder.layers.17.final_layer_norm.weight',\n",
              " 'model.decoder.layers.17.final_layer_norm.bias',\n",
              " 'model.decoder.layers.18.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.18.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.18.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.18.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.18.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.18.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.18.fc1.bias',\n",
              " 'model.decoder.layers.18.fc2.bias',\n",
              " 'model.decoder.layers.18.final_layer_norm.weight',\n",
              " 'model.decoder.layers.18.final_layer_norm.bias',\n",
              " 'model.decoder.layers.19.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.19.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.19.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.19.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.19.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.19.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.19.fc1.bias',\n",
              " 'model.decoder.layers.19.fc2.bias',\n",
              " 'model.decoder.layers.19.final_layer_norm.weight',\n",
              " 'model.decoder.layers.19.final_layer_norm.bias',\n",
              " 'model.decoder.layers.20.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.20.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.20.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.20.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.20.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.20.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.20.fc1.bias',\n",
              " 'model.decoder.layers.20.fc2.bias',\n",
              " 'model.decoder.layers.20.final_layer_norm.weight',\n",
              " 'model.decoder.layers.20.final_layer_norm.bias',\n",
              " 'model.decoder.layers.21.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.21.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.21.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.21.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.21.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.21.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.21.fc1.bias',\n",
              " 'model.decoder.layers.21.fc2.bias',\n",
              " 'model.decoder.layers.21.final_layer_norm.weight',\n",
              " 'model.decoder.layers.21.final_layer_norm.bias',\n",
              " 'model.decoder.layers.22.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.22.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.22.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.22.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.22.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.22.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.22.fc1.bias',\n",
              " 'model.decoder.layers.22.fc2.bias',\n",
              " 'model.decoder.layers.22.final_layer_norm.weight',\n",
              " 'model.decoder.layers.22.final_layer_norm.bias',\n",
              " 'model.decoder.layers.23.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.23.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.23.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.23.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.23.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.23.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.23.fc1.bias',\n",
              " 'model.decoder.layers.23.fc2.bias',\n",
              " 'model.decoder.layers.23.final_layer_norm.weight',\n",
              " 'model.decoder.layers.23.final_layer_norm.bias']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parms_of_dtype(prepared_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP3AX8C2P7zk",
        "outputId": "c8bd56d2-a70f-4385-db0e-92e73c66f84c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.decoder.embed_tokens.weight',\n",
              " 'model.decoder.embed_positions.weight',\n",
              " 'model.decoder.layers.0.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.0.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.0.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.0.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.0.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.0.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.0.fc1.bias',\n",
              " 'model.decoder.layers.0.fc2.bias',\n",
              " 'model.decoder.layers.0.final_layer_norm.weight',\n",
              " 'model.decoder.layers.0.final_layer_norm.bias',\n",
              " 'model.decoder.layers.1.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.1.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.1.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.1.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.1.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.1.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.1.fc1.bias',\n",
              " 'model.decoder.layers.1.fc2.bias',\n",
              " 'model.decoder.layers.1.final_layer_norm.weight',\n",
              " 'model.decoder.layers.1.final_layer_norm.bias',\n",
              " 'model.decoder.layers.2.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.2.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.2.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.2.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.2.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.2.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.2.fc1.bias',\n",
              " 'model.decoder.layers.2.fc2.bias',\n",
              " 'model.decoder.layers.2.final_layer_norm.weight',\n",
              " 'model.decoder.layers.2.final_layer_norm.bias',\n",
              " 'model.decoder.layers.3.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.3.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.3.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.3.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.3.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.3.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.3.fc1.bias',\n",
              " 'model.decoder.layers.3.fc2.bias',\n",
              " 'model.decoder.layers.3.final_layer_norm.weight',\n",
              " 'model.decoder.layers.3.final_layer_norm.bias',\n",
              " 'model.decoder.layers.4.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.4.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.4.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.4.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.4.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.4.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.4.fc1.bias',\n",
              " 'model.decoder.layers.4.fc2.bias',\n",
              " 'model.decoder.layers.4.final_layer_norm.weight',\n",
              " 'model.decoder.layers.4.final_layer_norm.bias',\n",
              " 'model.decoder.layers.5.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.5.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.5.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.5.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.5.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.5.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.5.fc1.bias',\n",
              " 'model.decoder.layers.5.fc2.bias',\n",
              " 'model.decoder.layers.5.final_layer_norm.weight',\n",
              " 'model.decoder.layers.5.final_layer_norm.bias',\n",
              " 'model.decoder.layers.6.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.6.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.6.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.6.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.6.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.6.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.6.fc1.bias',\n",
              " 'model.decoder.layers.6.fc2.bias',\n",
              " 'model.decoder.layers.6.final_layer_norm.weight',\n",
              " 'model.decoder.layers.6.final_layer_norm.bias',\n",
              " 'model.decoder.layers.7.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.7.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.7.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.7.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.7.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.7.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.7.fc1.bias',\n",
              " 'model.decoder.layers.7.fc2.bias',\n",
              " 'model.decoder.layers.7.final_layer_norm.weight',\n",
              " 'model.decoder.layers.7.final_layer_norm.bias',\n",
              " 'model.decoder.layers.8.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.8.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.8.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.8.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.8.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.8.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.8.fc1.bias',\n",
              " 'model.decoder.layers.8.fc2.bias',\n",
              " 'model.decoder.layers.8.final_layer_norm.weight',\n",
              " 'model.decoder.layers.8.final_layer_norm.bias',\n",
              " 'model.decoder.layers.9.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.9.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.9.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.9.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.9.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.9.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.9.fc1.bias',\n",
              " 'model.decoder.layers.9.fc2.bias',\n",
              " 'model.decoder.layers.9.final_layer_norm.weight',\n",
              " 'model.decoder.layers.9.final_layer_norm.bias',\n",
              " 'model.decoder.layers.10.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.10.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.10.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.10.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.10.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.10.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.10.fc1.bias',\n",
              " 'model.decoder.layers.10.fc2.bias',\n",
              " 'model.decoder.layers.10.final_layer_norm.weight',\n",
              " 'model.decoder.layers.10.final_layer_norm.bias',\n",
              " 'model.decoder.layers.11.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.11.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.11.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.11.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.11.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.11.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.11.fc1.bias',\n",
              " 'model.decoder.layers.11.fc2.bias',\n",
              " 'model.decoder.layers.11.final_layer_norm.weight',\n",
              " 'model.decoder.layers.11.final_layer_norm.bias',\n",
              " 'model.decoder.layers.12.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.12.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.12.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.12.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.12.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.12.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.12.fc1.bias',\n",
              " 'model.decoder.layers.12.fc2.bias',\n",
              " 'model.decoder.layers.12.final_layer_norm.weight',\n",
              " 'model.decoder.layers.12.final_layer_norm.bias',\n",
              " 'model.decoder.layers.13.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.13.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.13.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.13.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.13.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.13.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.13.fc1.bias',\n",
              " 'model.decoder.layers.13.fc2.bias',\n",
              " 'model.decoder.layers.13.final_layer_norm.weight',\n",
              " 'model.decoder.layers.13.final_layer_norm.bias',\n",
              " 'model.decoder.layers.14.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.14.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.14.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.14.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.14.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.14.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.14.fc1.bias',\n",
              " 'model.decoder.layers.14.fc2.bias',\n",
              " 'model.decoder.layers.14.final_layer_norm.weight',\n",
              " 'model.decoder.layers.14.final_layer_norm.bias',\n",
              " 'model.decoder.layers.15.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.15.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.15.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.15.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.15.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.15.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.15.fc1.bias',\n",
              " 'model.decoder.layers.15.fc2.bias',\n",
              " 'model.decoder.layers.15.final_layer_norm.weight',\n",
              " 'model.decoder.layers.15.final_layer_norm.bias',\n",
              " 'model.decoder.layers.16.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.16.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.16.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.16.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.16.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.16.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.16.fc1.bias',\n",
              " 'model.decoder.layers.16.fc2.bias',\n",
              " 'model.decoder.layers.16.final_layer_norm.weight',\n",
              " 'model.decoder.layers.16.final_layer_norm.bias',\n",
              " 'model.decoder.layers.17.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.17.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.17.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.17.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.17.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.17.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.17.fc1.bias',\n",
              " 'model.decoder.layers.17.fc2.bias',\n",
              " 'model.decoder.layers.17.final_layer_norm.weight',\n",
              " 'model.decoder.layers.17.final_layer_norm.bias',\n",
              " 'model.decoder.layers.18.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.18.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.18.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.18.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.18.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.18.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.18.fc1.bias',\n",
              " 'model.decoder.layers.18.fc2.bias',\n",
              " 'model.decoder.layers.18.final_layer_norm.weight',\n",
              " 'model.decoder.layers.18.final_layer_norm.bias',\n",
              " 'model.decoder.layers.19.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.19.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.19.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.19.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.19.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.19.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.19.fc1.bias',\n",
              " 'model.decoder.layers.19.fc2.bias',\n",
              " 'model.decoder.layers.19.final_layer_norm.weight',\n",
              " 'model.decoder.layers.19.final_layer_norm.bias',\n",
              " 'model.decoder.layers.20.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.20.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.20.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.20.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.20.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.20.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.20.fc1.bias',\n",
              " 'model.decoder.layers.20.fc2.bias',\n",
              " 'model.decoder.layers.20.final_layer_norm.weight',\n",
              " 'model.decoder.layers.20.final_layer_norm.bias',\n",
              " 'model.decoder.layers.21.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.21.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.21.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.21.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.21.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.21.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.21.fc1.bias',\n",
              " 'model.decoder.layers.21.fc2.bias',\n",
              " 'model.decoder.layers.21.final_layer_norm.weight',\n",
              " 'model.decoder.layers.21.final_layer_norm.bias',\n",
              " 'model.decoder.layers.22.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.22.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.22.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.22.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.22.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.22.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.22.fc1.bias',\n",
              " 'model.decoder.layers.22.fc2.bias',\n",
              " 'model.decoder.layers.22.final_layer_norm.weight',\n",
              " 'model.decoder.layers.22.final_layer_norm.bias',\n",
              " 'model.decoder.layers.23.self_attn.k_proj.bias',\n",
              " 'model.decoder.layers.23.self_attn.v_proj.bias',\n",
              " 'model.decoder.layers.23.self_attn.q_proj.bias',\n",
              " 'model.decoder.layers.23.self_attn.out_proj.bias',\n",
              " 'model.decoder.layers.23.self_attn_layer_norm.weight',\n",
              " 'model.decoder.layers.23.self_attn_layer_norm.bias',\n",
              " 'model.decoder.layers.23.fc1.bias',\n",
              " 'model.decoder.layers.23.fc2.bias',\n",
              " 'model.decoder.layers.23.final_layer_norm.weight',\n",
              " 'model.decoder.layers.23.final_layer_norm.bias']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for name, param in model_q4.named_parameters():\n",
        "  print(f\"Name: {name}, Shape: {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzWME0g9KUbb",
        "outputId": "fdee4076-fd7e-45ad-ef7e-b258e59d5f82"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: model.decoder.embed_tokens.weight, Shape: torch.Size([50272, 512])\n",
            "Name: model.decoder.embed_positions.weight, Shape: torch.Size([2050, 1024])\n",
            "Name: model.decoder.project_out.weight, Shape: torch.Size([262144, 1])\n",
            "Name: model.decoder.project_in.weight, Shape: torch.Size([262144, 1])\n",
            "Name: model.decoder.layers.0.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.0.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.0.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.0.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.0.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.0.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.0.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.0.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.0.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.0.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.0.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.0.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.0.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.0.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.0.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.0.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.1.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.1.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.1.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.1.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.1.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.1.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.1.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.1.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.2.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.2.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.2.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.2.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.2.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.2.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.2.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.2.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.3.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.3.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.3.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.3.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.3.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.3.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.3.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.3.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.4.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.4.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.4.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.4.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.4.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.4.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.4.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.4.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.5.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.5.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.5.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.5.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.5.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.5.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.5.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.5.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.6.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.6.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.6.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.6.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.6.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.6.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.6.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.6.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.7.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.7.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.7.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.7.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.7.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.7.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.7.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.7.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.8.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.8.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.8.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.8.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.8.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.8.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.8.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.8.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.9.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.9.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.9.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.9.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.9.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.9.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.9.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.9.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.10.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.10.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.10.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.10.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.10.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.10.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.10.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.10.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.11.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.11.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.11.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.11.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.11.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.11.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.11.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.11.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.12.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.12.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.12.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.12.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.12.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.12.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.12.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.12.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.13.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.13.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.13.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.13.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.13.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.13.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.13.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.13.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.14.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.14.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.14.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.14.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.14.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.14.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.14.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.14.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.15.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.15.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.15.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.15.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.15.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.15.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.15.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.15.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.16.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.16.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.16.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.16.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.16.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.16.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.16.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.16.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.17.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.17.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.17.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.17.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.17.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.17.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.17.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.17.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.18.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.18.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.18.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.18.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.18.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.18.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.18.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.18.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.19.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.19.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.19.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.19.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.19.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.19.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.19.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.19.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.20.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.20.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.20.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.20.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.20.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.20.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.20.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.20.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.21.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.21.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.21.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.21.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.21.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.21.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.21.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.21.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.22.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.22.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.22.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.22.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.22.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.22.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.22.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.22.final_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.self_attn.k_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.23.self_attn.k_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.self_attn.v_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.23.self_attn.v_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.self_attn.q_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.23.self_attn.q_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.self_attn.out_proj.weight, Shape: torch.Size([524288, 1])\n",
            "Name: model.decoder.layers.23.self_attn.out_proj.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.self_attn_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.self_attn_layer_norm.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.fc1.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.23.fc1.bias, Shape: torch.Size([4096])\n",
            "Name: model.decoder.layers.23.fc2.weight, Shape: torch.Size([2097152, 1])\n",
            "Name: model.decoder.layers.23.fc2.bias, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.final_layer_norm.weight, Shape: torch.Size([1024])\n",
            "Name: model.decoder.layers.23.final_layer_norm.bias, Shape: torch.Size([1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_model.get_memory_footprint()/1e6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaOFM1leKemn",
        "outputId": "75d68b66-f876-4b51-d662-135e33f2364c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "264.15104"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E1Dkf1wXLKIh"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTUPJ8xROk7Q"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWIe8BKEOrFS"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "yE819-ZGOu1H"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "soCuXe8EOxVT"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BF3x6dqoOzKp"
      },
      "execution_count": 77,
      "outputs": []
    }
  ]
}